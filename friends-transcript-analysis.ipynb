{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1331278,"sourceType":"datasetVersion","datasetId":772761}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport nltk\nimport spacy\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.probability import FreqDist\nnltk.download(\"punkt\")\nnltk.download(\"stopwords\")\nfrom spacy import displacy\nfrom PIL import Image\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n# Check if TensorFlow is already initialized\nif tf.test.is_built_with_cuda():\n    print(\"TensorFlow is already initialized with CUDA support\")\nelse:\n    # Initialize TensorFlow or other libraries here\n    pass\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom wordcloud import WordCloud","metadata":{"execution":{"iopub.status.busy":"2024-08-04T12:27:49.935562Z","iopub.execute_input":"2024-08-04T12:27:49.936786Z","iopub.status.idle":"2024-08-04T12:27:49.949181Z","shell.execute_reply.started":"2024-08-04T12:27:49.936735Z","shell.execute_reply":"2024-08-04T12:27:49.947370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loading the data","metadata":{}},{"cell_type":"code","source":"path = \"/kaggle/input/friends-tv-show-script/Friends_Transcript.txt\"\ntext = open(path, 'r').read()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T12:28:08.853315Z","iopub.execute_input":"2024-08-04T12:28:08.853799Z","iopub.status.idle":"2024-08-04T12:28:08.940291Z","shell.execute_reply.started":"2024-08-04T12:28:08.853761Z","shell.execute_reply":"2024-08-04T12:28:08.938816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sample of the transcript","metadata":{}},{"cell_type":"code","source":"text[:1000]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T12:28:29.016630Z","iopub.execute_input":"2024-08-04T12:28:29.017076Z","iopub.status.idle":"2024-08-04T12:28:29.026268Z","shell.execute_reply.started":"2024-08-04T12:28:29.017041Z","shell.execute_reply":"2024-08-04T12:28:29.024780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What are the most frequently used words or phrases?","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\nstopword = nltk.corpus.stopwords.words('english')\n\ndef textCleaning(text):\n    \n    text = re.sub(r'[^\\w\\s]', '', str(text))\n    text = re.split(\"\\W+\", text)\n    text = [word for word in text if word not in stopword]\n    text = ' '.join(text)\n    return text\n\n\ndef wordFrequency(text):\n    cleanText = textCleaning(text)\n    split_text = pd.DataFrame(cleanText.split(), columns=[\"Words\"])\n    split_text = split_text.value_counts()[:2500].reset_index(drop=False)[:2500]\n    split_text.columns = [\"Words\", \"Count\"]\n    return split_text","metadata":{"execution":{"iopub.status.busy":"2024-08-04T12:35:20.238368Z","iopub.execute_input":"2024-08-04T12:35:20.238894Z","iopub.status.idle":"2024-08-04T12:35:21.891355Z","shell.execute_reply.started":"2024-08-04T12:35:20.238824Z","shell.execute_reply":"2024-08-04T12:35:21.889434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frequentWords = wordFrequency(text)\nfrequentWords[:10].style.background_gradient(cmap=\"Blues\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T12:36:37.586206Z","iopub.execute_input":"2024-08-04T12:36:37.586652Z","iopub.status.idle":"2024-08-04T12:36:40.846300Z","shell.execute_reply.started":"2024-08-04T12:36:37.586617Z","shell.execute_reply":"2024-08-04T12:36:40.844940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.funnel(frequentWords[:10], x=\"Count\", y=\"Words\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T12:37:36.365424Z","iopub.execute_input":"2024-08-04T12:37:36.366070Z","iopub.status.idle":"2024-08-04T12:37:38.915355Z","shell.execute_reply.started":"2024-08-04T12:37:36.366020Z","shell.execute_reply":"2024-08-04T12:37:38.913736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = []\nfor i in frequentWords.Words:\n    words.append(str(i))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T12:38:40.127131Z","iopub.execute_input":"2024-08-04T12:38:40.127620Z","iopub.status.idle":"2024-08-04T12:38:40.136902Z","shell.execute_reply.started":"2024-08-04T12:38:40.127584Z","shell.execute_reply":"2024-08-04T12:38:40.134982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud = WordCloud(width=250, height=250,\n                     background_color=\"black\",\n                     stopwords = stopword,\n                     min_font_size = 10).generate(' '.join(words))\n\nplt.figure(figsize=(8,8), facecolor=None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T12:58:05.819148Z","iopub.execute_input":"2024-08-04T12:58:05.819701Z","iopub.status.idle":"2024-08-04T12:58:06.299181Z","shell.execute_reply.started":"2024-08-04T12:58:05.819658Z","shell.execute_reply":"2024-08-04T12:58:06.297620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How do different characters contribute to the dialogue?\n\nAnalyze the distribution of dialogue among characters to see who speaks the most and their role in the series.","metadata":{}},{"cell_type":"code","source":"name_list = ['Joey','Monica','Phoebe','Chandler','Ross','Rachel']\nscripts = []\nsplit_string = text.split()\nfor name in name_list:\n    scripts.append((name,split_string.count(name)))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:07:50.724911Z","iopub.execute_input":"2024-08-04T13:07:50.726297Z","iopub.status.idle":"2024-08-04T13:07:50.984628Z","shell.execute_reply.started":"2024-08-04T13:07:50.726248Z","shell.execute_reply":"2024-08-04T13:07:50.983026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = ['#2F86A6','#34BE82','#2FDD92','#F2F013','#F9975D','#F4E185']\nsections = [scripts[0][1],\n            scripts[1][1],\n            scripts[2][1],\n            scripts[3][1],\n           scripts[4][1],\n           scripts[5][1]]\nplt.figure(figsize=(14, 8), dpi=75)\nplt.pie(sections, labels=name_list,colors=colors, \n        wedgeprops=dict( alpha=1),\n        startangle=90,\n        #explode = (0,0,0,0),\n        autopct = '%0.1f%%',\n         textprops={\n                'fontsize': 15, \n                'fontweight': 'normal'}\n            )\n\nplt.axis('equal')\nplt.title('Script Count',fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:08:06.337497Z","iopub.execute_input":"2024-08-04T13:08:06.337934Z","iopub.status.idle":"2024-08-04T13:08:06.632985Z","shell.execute_reply.started":"2024-08-04T13:08:06.337897Z","shell.execute_reply":"2024-08-04T13:08:06.631708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What are the key topics or themes discussed in the series?","metadata":{}},{"cell_type":"code","source":"def preprocess_text(text):\n    # Convert to lowercase\n    text = text.lower()\n    # Remove punctuation and numbers\n    text = re.sub(r'[^a-z\\s]', '', text)\n    # Tokenize\n    tokens = word_tokenize(text)\n    # Remove stopwords\n    tokens = [word for word in tokens if word not in stopwords.words('english')]\n    # Join tokens back into string\n    return ' '.join(tokens)\n\n# Preprocess the transcript\ncleaned_transcript = preprocess_text(text)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:12:38.614274Z","iopub.execute_input":"2024-08-04T13:12:38.614897Z","iopub.status.idle":"2024-08-04T13:15:05.120283Z","shell.execute_reply.started":"2024-08-04T13:12:38.614840Z","shell.execute_reply":"2024-08-04T13:15:05.118813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create TF-IDF vectorizer\nvectorizer = TfidfVectorizer(stop_words='english')\nX = vectorizer.fit_transform([cleaned_transcript])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:17:00.025506Z","iopub.execute_input":"2024-08-04T13:17:00.026097Z","iopub.status.idle":"2024-08-04T13:17:00.725635Z","shell.execute_reply.started":"2024-08-04T13:17:00.026056Z","shell.execute_reply":"2024-08-04T13:17:00.724119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform topic modeling\nnum_topics = 5\nlda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\nlda.fit(X)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:17:10.286408Z","iopub.execute_input":"2024-08-04T13:17:10.286969Z","iopub.status.idle":"2024-08-04T13:17:10.565720Z","shell.execute_reply.started":"2024-08-04T13:17:10.286922Z","shell.execute_reply":"2024-08-04T13:17:10.563626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the top words for each topic\ndef display_topics(model, feature_names, no_top_words):\n    for topic_idx, topic in enumerate(model.components_):\n        print(f\"Topic #{topic_idx}:\")\n        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n    print()\n\ntfidf_feature_names = vectorizer.get_feature_names_out()\ndisplay_topics(lda, tfidf_feature_names, no_top_words=10)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:17:27.410707Z","iopub.execute_input":"2024-08-04T13:17:27.411269Z","iopub.status.idle":"2024-08-04T13:17:27.455226Z","shell.execute_reply.started":"2024-08-04T13:17:27.411230Z","shell.execute_reply":"2024-08-04T13:17:27.453744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install vaderSentiment","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:22:06.067567Z","iopub.execute_input":"2024-08-04T13:22:06.068049Z","iopub.status.idle":"2024-08-04T13:22:23.958323Z","shell.execute_reply.started":"2024-08-04T13:22:06.068016Z","shell.execute_reply":"2024-08-04T13:22:23.956533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n\nanalyzer = SentimentIntensityAnalyzer()\ndef preprocess_and_split(text):\n    # Split by multiple newlines\n    segments = re.split(r'\\n{2,}', text)\n    return segments\n\nsegments = preprocess_and_split(text)\n\ndef analyze_sentiment(text):\n    return analyzer.polarity_scores(text)\n\nsentiments = [analyze_sentiment(segment) for segment in segments]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:23:40.756830Z","iopub.execute_input":"2024-08-04T13:23:40.757260Z","iopub.status.idle":"2024-08-04T13:34:16.465842Z","shell.execute_reply.started":"2024-08-04T13:23:40.757227Z","shell.execute_reply":"2024-08-04T13:34:16.463424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}